{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic prediction - competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set seed to always be used\n",
    "seed = 123\n",
    "\n",
    "\n",
    "def preprocess(train, test):\n",
    "    train['test_train'] = 'train'\n",
    "    test['test_train'] = 'test'\n",
    "    data = pd.concat([test,train], sort = True)\n",
    "    data['Cabin_dep'] = [cabin_no[0] for cabin_no in data['Cabin'].astype(\"str\") if cabin_no.lower() != \"nan\"]\n",
    "    data['Cabin_dep'] = data['Cabin_dep'].astype('category')\n",
    "    \n",
    "    data = data.drop(['Cabin', 'Name',], axis = 1)\n",
    "    \n",
    "    ### Fix the age variable\n",
    "    \n",
    "    from matplotlib.pyplot import hist\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    from scipy.stats import gaussian_kde\n",
    "    hist(data['Age'].dropna(), density = True)\n",
    "\n",
    "    from scipy.stats import poisson\n",
    "\n",
    "    dens = gaussian_kde(data['Age'].dropna())\n",
    "    x = np.arange(0,data['Age'].dropna().max())\n",
    "    plt.plot(x, dens.evaluate(x), 'r')\n",
    "\n",
    "    dist = dens.evaluate(x)\n",
    "    # Normalize\n",
    "\n",
    "    dist = np.divide(dist,np.sum(dist))\n",
    "\n",
    "    # We should sample out of this distribution to compensate. \n",
    "    np.random.seed(seed)\n",
    "    nan_ages = np.random.choice(x, p = dist, size = data['Age'].isnull().sum(), )\n",
    "\n",
    "    count = 0\n",
    "    for i in range(data.shape[0]):\n",
    "        if np.isnan(data['Age'][i]):\n",
    "            data['Age'][i] = nan_ages[count]\n",
    "            count += 1\n",
    "            \n",
    "    data['Cabin'] = data['Cabin'].fillna(\"Unknown\")\n",
    "    \n",
    "    \n",
    "    # Done processing. Return it\n",
    "    test, train = [x for _, x in data.groupby(data['train_test'] == \"train\")]\n",
    "    test.drop(['train_test'],axis=1)\n",
    "    train.drop(['train_test'],axis=1)\n",
    "    # return data\n",
    "    \n",
    "    return train, test\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "data = pd.concat([test,train], sort = False)\n",
    "data = data.reset_index()\n",
    "#train, test = preprocess(train, test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1014\n"
     ]
    }
   ],
   "source": [
    "print(data['Cabin'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Cabin_dep'] = [cabin_no[0] for cabin_no in data['Cabin'].astype(\"str\")]\n",
    "#data['Cabin_dep'] = [None for cabin_no in data['Cabin'].astype(\"str\")]\n",
    "data['Cabin_dep'] = data['Cabin_dep'].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing age variable\n",
    "\n",
    "As we saw, we have many ages that are NaN. To compensate for this, we simulate the distribution and obtain new samples. Make sure to use seed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.pyplot import hist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "hist(data['Age'].dropna(), density = True)\n",
    "\n",
    "from scipy.stats import poisson\n",
    "\n",
    "dens = gaussian_kde(data['Age'].dropna())\n",
    "x = np.arange(0,data['Age'].dropna().max())\n",
    "plt.plot(x, dens.evaluate(x), 'r')\n",
    "\n",
    "dist = dens.evaluate(x)\n",
    "# Normalize\n",
    "\n",
    "dist = np.divide(dist,np.sum(dist))\n",
    "\n",
    "# We should sample out of this distribution to compensate. \n",
    "np.random.seed(seed)\n",
    "nan_ages = np.random.choice(x, p = dist, size = data['Age'].isnull().sum(), )\n",
    "\n",
    "count = 0\n",
    "#print(data)\n",
    "for i in range(data.shape[0]):\n",
    "    if np.isnan(data['Age'][i]):\n",
    "        data['Age'][i] = nan_ages[count]\n",
    "        count += 1\n",
    "        \n",
    "print(data['Age'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index             0\n",
       "PassengerId       0\n",
       "Pclass            0\n",
       "Name              0\n",
       "Sex               0\n",
       "Age               0\n",
       "SibSp             0\n",
       "Parch             0\n",
       "Ticket            0\n",
       "Fare              1\n",
       "Cabin          1014\n",
       "Embarked          2\n",
       "Survived        418\n",
       "Cabin_dep         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so we need to fix Fare as well. Just take the mean here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Fare'] = data['Fare'].fillna(data['Fare'].dropna().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data['Sex'] = data['Sex'].astype('str')\n",
    "data['Sex'] = data['Sex'].replace({'male':1, 'female':-1})\n",
    "\n",
    "# Drop unnecessary frames not interesting. \n",
    "\n",
    "data = data.drop(['Name','Ticket','Cabin'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index  PassengerId  Pclass  Sex   Age  SibSp  Parch     Fare Embarked  \\\n",
      "418      0            1       3    1  22.0      1      0   7.2500        S   \n",
      "419      1            2       1   -1  38.0      1      0  71.2833        C   \n",
      "420      2            3       3   -1  26.0      0      0   7.9250        S   \n",
      "421      3            4       1   -1  35.0      1      0  53.1000        S   \n",
      "422      4            5       3    1  35.0      0      0   8.0500        S   \n",
      "\n",
      "     Survived Cabin_dep  \n",
      "418       0.0         n  \n",
      "419       1.0         C  \n",
      "420       1.0         n  \n",
      "421       1.0         C  \n",
      "422       0.0         n  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Cabin_dep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  PassengerId  Pclass  Sex   Age  SibSp  Parch     Fare Embarked  \\\n",
       "0      0          892       3    1  34.5      0      0   7.8292        Q   \n",
       "1      1          893       3   -1  47.0      1      0   7.0000        S   \n",
       "2      2          894       2    1  62.0      0      0   9.6875        Q   \n",
       "3      3          895       3    1  27.0      0      0   8.6625        S   \n",
       "4      4          896       3   -1  22.0      1      1  12.2875        S   \n",
       "\n",
       "   Survived Cabin_dep  \n",
       "0       NaN         n  \n",
       "1       NaN         n  \n",
       "2       NaN         n  \n",
       "3       NaN         n  \n",
       "4       NaN         n  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = [x for _, x in data.groupby(data['Survived'].isnull())]\n",
    "print(train.head())\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing done - time for modelling\n",
    "\n",
    "First off, we simply try a ridge regression with an rbf kernel and see its performance. This is kind of unchristly as it is actually regression, but it might actually perform well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1.0, 'coef0': 1, 'degree': 3, 'gamma': None, 'kernel': 'rbf', 'kernel_params': None}\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params\n",
      "{'alpha': 0.1, 'coef0': 0, 'degree': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 405 out of 405 | elapsed:   20.9s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "kern_ridge = KernelRidge(alpha=1.0, kernel = 'rbf')\n",
    "\n",
    "X = train.drop(['index', 'PassengerId','Survived', 'Embarked', 'Cabin_dep'], axis = 1)\n",
    "y = train['Survived']\n",
    "\n",
    "print(kern_ridge.get_params())\n",
    "\n",
    "params = {'alpha': [0.01,0.1, 1.0],\n",
    " 'coef0': [0,0.1,1],\n",
    " 'degree': [1,2,3],\n",
    " 'gamma': [0.01,1,10],\n",
    " 'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "grid_search = GridSearchCV(estimator=kern_ridge, param_grid = params, n_jobs = 1, iid=False,verbose=True, scoring = 'neg_mean_squared_error', cv = 5)\n",
    "grid_search.fit(X,y)\n",
    "print(\"Best params\")\n",
    "print(grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use the best hyperparameters obtained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "best_model = KernelRidge(alpha=0.1, coef0=0, degree=1, gamma=0.01, kernel = 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[505,  44],\n",
       "       [ 55, 287]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X,y)\n",
    "\n",
    "y_preds = best_model.predict(X)\n",
    "preds = []\n",
    "for i in range(len(y_preds)):\n",
    "    if y_preds[i] < 0.5:\n",
    "        preds.append(0)\n",
    "    else:\n",
    "        preds.append(1)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y,preds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good. Now lets try logistic regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'max_iter': 100, 'multi_class': 'ovr', 'n_jobs': 1, 'penalty': 'l2', 'random_state': None, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 240 out of 240 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=False, n_jobs=1,\n",
       "       param_grid={'C': [0.1, 1.0, 10, 100], 'class_weight': [None], 'dual': [None], 'fit_intercept': [True, False], 'max_iter': [10000], 'multi_class': ['ovr'], 'n_jobs': [1], 'penalty': ['l1', 'l2'], 'random_state': [123], 'tol': [0.0001, 0.0005, 0.001], 'solver': ['saga'], 'warm_start': [False]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg_model = LogisticRegression()\n",
    "\n",
    "print(log_reg_model.get_params())\n",
    "X = train.drop(['index', 'PassengerId','Survived', 'Embarked', 'Cabin_dep'], axis = 1)\n",
    "y = y.astype(\"category\")\n",
    "log_reg_params = {'C': [0.1,1.0,10,100], \n",
    "                  'class_weight': [None], \n",
    "                  'dual': [None], \n",
    "                  'fit_intercept': [True,False], \n",
    "                  'max_iter': [10000], \n",
    "                  'multi_class': ['ovr'], \n",
    "                  'n_jobs': [1],\n",
    "                  'penalty': ['l1','l2'],\n",
    "                  'random_state': [123],  \n",
    "                  'tol': [0.0001, 0.0005,0.001], \n",
    "                  'solver':['saga'],\n",
    "                  'warm_start': [False]}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=log_reg_model, param_grid = log_reg_params, n_jobs = 1, iid=False,verbose=True, cv = 5)\n",
    "grid_search.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'class_weight': None, 'dual': None, 'fit_intercept': False, 'max_iter': 10000, 'multi_class': 'ovr', 'n_jobs': 1, 'penalty': 'l1', 'random_state': 123, 'solver': 'saga', 'tol': 0.0005, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[475,  74],\n",
       "       [108, 234]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_log_reg = LogisticRegression(C=10, fit_intercept=False,max_iter=10000, multi_class=\"ovr\",n_jobs=1,penalty=\"l1\", random_state=123, solver=\"saga\", tol=0.0005, warm_start=False)\n",
    "\n",
    "best_log_reg.fit(X,y)\n",
    "log_reg_preds = best_log_reg.predict(X)\n",
    "confusion_matrix(y, log_reg_preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So Logistic regression performed worse. Let's choose the Ridge Regression for the classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop(['index', 'PassengerId','Survived', 'Embarked', 'Cabin_dep'], axis = 1)\n",
    "X_test.head()\n",
    "y_preds_test = best_model.predict(X_test)\n",
    "preds_test = []\n",
    "for i in range(len(y_preds_test)):\n",
    "    if y_preds_test[i] < 0.5:\n",
    "        preds_test.append(0)\n",
    "    else:\n",
    "        preds_test.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([test['PassengerId'], pd.Series(preds_test)], axis=1)\n",
    "submission.columns = ['PassengerId', 'Survived']\n",
    "submission.head()\n",
    "submission.to_csv(\"submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
