#nb_model_10 = naiveBayes(score_grp_10 ~., data = train10)
nb_model_10 = train(x=train10[,-c(6)],y=train10[,6], "nb", trControl = trainControl(method = "cv", number = 10))
test_preds = predict(nb_model_10, test10)
conf_m = table(test10$score_grp_10, test_preds)
print(paste("Misclassification rate is",1 - sum(diag(conf_m))/sum(conf_m)))
calc_max_MSE(conf_m)
calc_max_MSE = function(conf_m) {
# For each that
max_SSE = 0
min_SSE = 0
score_step_by_class = (100/nrow(conf_m))
max_possible_err_inside_class = score_step_by_class - 1
n = sum(conf_m)
for (i in 1:nrow(conf_m)) {
for (j in 1:ncol(conf_m)) {
# Take the distance from the diagonal
if (i != j && conf_m[i,j] > 0) {
min_SSE = min_SSE + (1 + abs((i - j - 1)*score_step_by_class))^2
max_SSE = max_SSE + (max_possible_err_inside_class + abs(score_step_by_class*(i-j)))^2
} else if (i == j) { # They can still be far away.
max_SSE = max_SSE + max_possible_err_inside_class^2
}
}
}
max_mse = (1/n)*max_SSE
min_mse = (1/n)*min_SSE
print(paste("The MSE for this model on the test set will lie between", min_mse, "and", max_mse))
print(paste("This is a deviation of around", sqrt(min_mse), "and", sqrt(max_mse)))
}
calc_avg = function(data) {
avg_score = as.numeric()
for (i in 1:nrow(data)) {
avg_score[i] = (data$math.score[i] + data$reading.score[i] + data$writing.score[i])/3
}
return(avg_score)
}
data = read.csv("StudentsPerformance.csv")
data$average_score = calc_avg(data)
data$score_grp_5 = cut(data$reading.score, breaks = seq(0,100,by = 5), right = TRUE)
data$score_grp_5 = factor(data$score_grp_5, levels = levels(data$score_grp_5)[table(data$score_grp_5) > 0])
data$score_grp_2 = cut(data$reading.score, breaks = seq(0,100,by = 2), right = TRUE)
data$score_grp_2 = factor(data$score_grp_2, levels = levels(data$score_grp_2)[table(data$score_grp_2) > 0])
data$score_grp_4 = cut(data$reading.score, breaks = seq(0,100,by = 4), right = TRUE)
data$score_grp_4 = factor(data$score_grp_4, levels = levels(data$score_grp_4)[table(data$score_grp_4) > 0])
data$score_grp_10 = cut(data$reading.score, breaks = seq(0,100,by = 10), right = TRUE)
data = data[,-c(6,7,8,9)]
n=dim(data)[1]
set.seed(12345)
id=sample(1:n, floor(n*0.5))
train=data[id,]
test=data[-id,]
#library(e1071)
library(caret)
train5 = train[,-c(7,8,9)]
test5 = test[,-c(7,8,9)]
#nb_model_5 = naiveBayes(score_grp_5~., data = train5)
nb_model_5 = train(x=train5[,-c(6)],y=train5[,6], "nb", trControl = trainControl(method = "cv", number = 10))
test_preds = predict(nb_model_5, test5)
conf_m = table(Actual = test5$score_grp_5, Predicted = test_preds)
print(paste("Misclassification rate is",1 - sum(diag(conf_m))/sum(conf_m)))
calc_max_MSE(conf_m)
train2 = train[,-c(6,8,9)]
test2 = test[,-c(6,8,9)]
#nb_model_2 = naiveBayes(score_grp_2 ~., data = train2)
nb_model_2 = train(x=train2[,-c(6)],y=train2[,6], "nb", trControl = trainControl(method = "cv", number = 10))
test_preds = predict(nb_model_2, test2)
conf_m = table(test2$score_grp_2, test_preds)
print(paste("Misclassification rate is",1 - sum(diag(conf_m))/sum(conf_m)))
calc_max_MSE(conf_m)
train4 = train[,-c(6,7,9)]
test4 = train[,-c(6,7,9)]
#nb_model_4 = naiveBayes(score_grp_4 ~., data = train4)
nb_model_4 = train(x=train4[,-c(6)],y=train4[,6], "nb", trControl = trainControl(method = "cv", number = 10))
test_preds = predict(nb_model_4, test4)
conf_m = table(test4$score_grp_4, test_preds)
print(paste("Misclassification rate is",1 - sum(diag(conf_m))/sum(conf_m)))
calc_max_MSE(conf_m)
train10 = train[,-c(6,7,8)]
test10 = test[,-c(6,7,8)]
#nb_model_10 = naiveBayes(score_grp_10 ~., data = train10)
nb_model_10 = train(x=train10[,-c(6)],y=train10[,6], "nb", trControl = trainControl(method = "cv", number = 10))
test_preds = predict(nb_model_10, test10)
conf_m = table(test10$score_grp_10, test_preds)
print(paste("Misclassification rate is",1 - sum(diag(conf_m))/sum(conf_m)))
calc_max_MSE(conf_m)
calc_max_MSE = function(conf_m) {
# For each that
max_SSE = 0
min_SSE = 0
score_step_by_class = (100/nrow(conf_m))
max_possible_err_inside_class = score_step_by_class - 1
n = sum(conf_m)
for (i in 1:nrow(conf_m)) {
for (j in 1:ncol(conf_m)) {
# Take the distance from the diagonal
if (i != j && conf_m[i,j] > 0) {
min_SSE = min_SSE + (1 + abs((i - j - 1)*score_step_by_class))^2
max_SSE = max_SSE + (max_possible_err_inside_class + abs(score_step_by_class*(i-j)))^2
} else if (i == j) { # They can still be far away.
max_SSE = max_SSE + max_possible_err_inside_class^2
}
}
}
max_mse = (1/n)*max_SSE
min_mse = (1/n)*min_SSE
print(paste("The MSE for this model on the test set will lie between", min_mse, "and", max_mse))
print(paste("This is a deviation of around", sqrt(min_mse), "and", sqrt(max_mse)))
}
calc_avg = function(data) {
avg_score = as.numeric()
for (i in 1:nrow(data)) {
avg_score[i] = (data$math.score[i] + data$reading.score[i] + data$writing.score[i])/3
}
return(avg_score)
}
data = read.csv("StudentsPerformance.csv")
data$average_score = calc_avg(data)
data$score_grp_5 = cut(data$reading.score, breaks = seq(0,100,by = 5), right = TRUE)
data$score_grp_5 = factor(data$score_grp_5, levels = levels(data$score_grp_5)[table(data$score_grp_5) > 0])
data$score_grp_2 = cut(data$reading.score, breaks = seq(0,100,by = 2), right = TRUE)
data$score_grp_2 = factor(data$score_grp_2, levels = levels(data$score_grp_2)[table(data$score_grp_2) > 0])
data$score_grp_4 = cut(data$reading.score, breaks = seq(0,100,by = 4), right = TRUE)
data$score_grp_4 = factor(data$score_grp_4, levels = levels(data$score_grp_4)[table(data$score_grp_4) > 0])
data$score_grp_10 = cut(data$reading.score, breaks = seq(0,100,by = 10), right = TRUE)
data = data[,-c(6,7,8,9)]
n=dim(data)[1]
set.seed(12345)
id=sample(1:n, floor(n*0.9))
train=data[id,]
test=data[-id,]
#library(e1071)
library(caret)
train5 = train[,-c(7,8,9)]
test5 = test[,-c(7,8,9)]
#nb_model_5 = naiveBayes(score_grp_5~., data = train5)
nb_model_5 = train(x=train5[,-c(6)],y=train5[,6], "nb", trControl = trainControl(method = "cv", number = 10))
test_preds = predict(nb_model_5, test5)
conf_m = table(Actual = test5$score_grp_5, Predicted = test_preds)
print(paste("Misclassification rate is",1 - sum(diag(conf_m))/sum(conf_m)))
calc_max_MSE(conf_m)
train2 = train[,-c(6,8,9)]
test2 = test[,-c(6,8,9)]
#nb_model_2 = naiveBayes(score_grp_2 ~., data = train2)
nb_model_2 = train(x=train2[,-c(6)],y=train2[,6], "nb", trControl = trainControl(method = "cv", number = 10))
test_preds = predict(nb_model_2, test2)
conf_m = table(test2$score_grp_2, test_preds)
print(paste("Misclassification rate is",1 - sum(diag(conf_m))/sum(conf_m)))
calc_max_MSE(conf_m)
train4 = train[,-c(6,7,9)]
test4 = train[,-c(6,7,9)]
#nb_model_4 = naiveBayes(score_grp_4 ~., data = train4)
nb_model_4 = train(x=train4[,-c(6)],y=train4[,6], "nb", trControl = trainControl(method = "cv", number = 10))
test_preds = predict(nb_model_4, test4)
conf_m = table(test4$score_grp_4, test_preds)
print(paste("Misclassification rate is",1 - sum(diag(conf_m))/sum(conf_m)))
calc_max_MSE(conf_m)
train10 = train[,-c(6,7,8)]
test10 = test[,-c(6,7,8)]
#nb_model_10 = naiveBayes(score_grp_10 ~., data = train10)
nb_model_10 = train(x=train10[,-c(6)],y=train10[,6], "nb", trControl = trainControl(method = "cv", number = 10))
test_preds = predict(nb_model_10, test10)
conf_m = table(test10$score_grp_10, test_preds)
print(paste("Misclassification rate is",1 - sum(diag(conf_m))/sum(conf_m)))
calc_max_MSE(conf_m)
calc_max_MSE = function(conf_m) {
# For each that
max_SSE = 0
min_SSE = 0
score_step_by_class = (100/nrow(conf_m))
max_possible_err_inside_class = score_step_by_class - 1
n = sum(conf_m)
for (i in 1:nrow(conf_m)) {
for (j in 1:ncol(conf_m)) {
# Take the distance from the diagonal
if (i != j && conf_m[i,j] > 0) {
min_SSE = min_SSE + (1 + abs((i - j - 1)*score_step_by_class))^2
max_SSE = max_SSE + (max_possible_err_inside_class + abs(score_step_by_class*(i-j)))^2
} else if (i == j) { # They can still be far away.
max_SSE = max_SSE + max_possible_err_inside_class^2
}
}
}
max_mse = (1/n)*max_SSE
min_mse = (1/n)*min_SSE
print(paste("The MSE for this model on the test set will lie between", min_mse, "and", max_mse))
print(paste("This is a deviation of around", sqrt(min_mse), "and", sqrt(max_mse)))
}
calc_avg = function(data) {
avg_score = as.numeric()
for (i in 1:nrow(data)) {
avg_score[i] = (data$math.score[i] + data$reading.score[i] + data$writing.score[i])/3
}
return(avg_score)
}
data = read.csv("StudentsPerformance.csv")
data$average_score = calc_avg(data)
data$score_grp_5 = cut(data$reading.score, breaks = seq(0,100,by = 5), right = TRUE)
data$score_grp_5 = factor(data$score_grp_5, levels = levels(data$score_grp_5)[table(data$score_grp_5) > 0])
data$score_grp_2 = cut(data$reading.score, breaks = seq(0,100,by = 2), right = TRUE)
data$score_grp_2 = factor(data$score_grp_2, levels = levels(data$score_grp_2)[table(data$score_grp_2) > 0])
data$score_grp_4 = cut(data$reading.score, breaks = seq(0,100,by = 4), right = TRUE)
data$score_grp_4 = factor(data$score_grp_4, levels = levels(data$score_grp_4)[table(data$score_grp_4) > 0])
data$score_grp_10 = cut(data$reading.score, breaks = seq(0,100,by = 10), right = TRUE)
data = data[,-c(6,7,8,9)]
n=dim(data)[1]
set.seed(12345)
id=sample(1:n, floor(n*0.75))
train=data[id,]
test=data[-id,]
#library(e1071)
library(caret)
train5 = train[,-c(7,8,9)]
test5 = test[,-c(7,8,9)]
#nb_model_5 = naiveBayes(score_grp_5~., data = train5)
nb_model_5 = train(x=train5[,-c(6)],y=train5[,6], "nb", trControl = trainControl(method = "cv", number = 10))
test_preds = predict(nb_model_5, test5)
conf_m = table(Actual = test5$score_grp_5, Predicted = test_preds)
print(paste("Misclassification rate is",1 - sum(diag(conf_m))/sum(conf_m)))
calc_max_MSE(conf_m)
train2 = train[,-c(6,8,9)]
test2 = test[,-c(6,8,9)]
#nb_model_2 = naiveBayes(score_grp_2 ~., data = train2)
nb_model_2 = train(x=train2[,-c(6)],y=train2[,6], "nb", trControl = trainControl(method = "cv", number = 10))
test_preds = predict(nb_model_2, test2)
conf_m = table(test2$score_grp_2, test_preds)
print(paste("Misclassification rate is",1 - sum(diag(conf_m))/sum(conf_m)))
calc_max_MSE(conf_m)
train4 = train[,-c(6,7,9)]
test4 = train[,-c(6,7,9)]
#nb_model_4 = naiveBayes(score_grp_4 ~., data = train4)
nb_model_4 = train(x=train4[,-c(6)],y=train4[,6], "nb", trControl = trainControl(method = "cv", number = 10))
test_preds = predict(nb_model_4, test4)
conf_m = table(test4$score_grp_4, test_preds)
print(paste("Misclassification rate is",1 - sum(diag(conf_m))/sum(conf_m)))
calc_max_MSE(conf_m)
train10 = train[,-c(6,7,8)]
test10 = test[,-c(6,7,8)]
#nb_model_10 = naiveBayes(score_grp_10 ~., data = train10)
nb_model_10 = train(x=train10[,-c(6)],y=train10[,6], "nb", trControl = trainControl(method = "cv", number = 10))
test_preds = predict(nb_model_10, test10)
conf_m = table(test10$score_grp_10, test_preds)
print(paste("Misclassification rate is",1 - sum(diag(conf_m))/sum(conf_m)))
calc_max_MSE(conf_m)
table(test10$score_grp_10, test_preds)
table(test4$score_grp_4, test_preds)
grades = as.character()
data = read.csv("StudentsPerformance.csv")
data$average_score = calc_avg(data)
calc_max_MSE = function(conf_m) {
# For each that
max_SSE = 0
min_SSE = 0
score_step_by_class = (100/nrow(conf_m))
max_possible_err_inside_class = score_step_by_class - 1
n = sum(conf_m)
for (i in 1:nrow(conf_m)) {
for (j in 1:ncol(conf_m)) {
# Take the distance from the diagonal
if (i != j && conf_m[i,j] > 0) {
min_SSE = min_SSE + (1 + abs((i - j - 1)*score_step_by_class))^2
max_SSE = max_SSE + (max_possible_err_inside_class + abs(score_step_by_class*(i-j)))^2
} else if (i == j) { # They can still be far away.
max_SSE = max_SSE + max_possible_err_inside_class^2
}
}
}
max_mse = (1/n)*max_SSE
min_mse = (1/n)*min_SSE
print(paste("The MSE for this model on the test set will lie between", min_mse, "and", max_mse))
print(paste("This is a deviation of around", sqrt(min_mse), "and", sqrt(max_mse)))
}
get_grades = function(avg_score) {
grades = as.character()
for (i in 1:length(avg_score)) {
if (avg_score[i] < 40) {
grades[i] = "F"
} else if (avg_score[i] < 50) {
grades[i] = "E"
} else if (avg_score[i] < 60) {
grades[i] = "D"
} else if (avg_score[i] < 70) {
grades[i] = "C"
} else if (avg_score[i] < 80) {
grades[i] = "B"
} else {
grades[i] = "A"
}
}
return(as.factor(grades))
}
calc_avg = function(data) {
avg_score = as.numeric()
for (i in 1:nrow(data)) {
avg_score[i] = (data$math.score[i] + data$reading.score[i] + data$writing.score[i])/3
}
return(avg_score)
}
data = read.csv("StudentsPerformance.csv")
data$average_score = calc_avg(data)
calc_max_MSE = function(conf_m) {
# For each that
max_SSE = 0
min_SSE = 0
score_step_by_class = (100/nrow(conf_m))
max_possible_err_inside_class = score_step_by_class - 1
n = sum(conf_m)
for (i in 1:nrow(conf_m)) {
for (j in 1:ncol(conf_m)) {
# Take the distance from the diagonal
if (i != j && conf_m[i,j] > 0) {
min_SSE = min_SSE + (1 + abs((i - j - 1)*score_step_by_class))^2
max_SSE = max_SSE + (max_possible_err_inside_class + abs(score_step_by_class*(i-j)))^2
} else if (i == j) { # They can still be far away.
max_SSE = max_SSE + max_possible_err_inside_class^2
}
}
}
max_mse = (1/n)*max_SSE
min_mse = (1/n)*min_SSE
print(paste("The MSE for this model on the test set will lie between", min_mse, "and", max_mse))
print(paste("This is a deviation of around", sqrt(min_mse), "and", sqrt(max_mse)))
}
get_grades = function(avg_score) {
grades = as.character()
for (i in 1:length(avg_score)) {
if (avg_score[i] < 40) {
grades[i] = "F"
} else if (avg_score[i] < 50) {
grades[i] = "E"
} else if (avg_score[i] < 60) {
grades[i] = "D"
} else if (avg_score[i] < 70) {
grades[i] = "C"
} else if (avg_score[i] < 80) {
grades[i] = "B"
} else {
grades[i] = "A"
}
}
return(as.factor(grades))
}
calc_avg = function(data) {
avg_score = as.numeric()
for (i in 1:nrow(data)) {
avg_score[i] = (data$math.score[i] + data$reading.score[i] + data$writing.score[i])/3
}
return(avg_score)
}
data = read.csv("StudentsPerformance.csv")
data$average_score = calc_avg(data)
data$score_grp_5 = cut(data$reading.score, breaks = seq(0,100,by = 5), right = TRUE)
data$score_grp_5 = factor(data$score_grp_5, levels = levels(data$score_grp_5)[table(data$score_grp_5) > 0])
data$score_grp_2 = cut(data$reading.score, breaks = seq(0,100,by = 2), right = TRUE)
data$score_grp_2 = factor(data$score_grp_2, levels = levels(data$score_grp_2)[table(data$score_grp_2) > 0])
data$score_grp_4 = cut(data$reading.score, breaks = seq(0,100,by = 4), right = TRUE)
data$score_grp_4 = factor(data$score_grp_4, levels = levels(data$score_grp_4)[table(data$score_grp_4) > 0])
data$score_grp_10 = cut(data$reading.score, breaks = seq(0,100,by = 10), right = TRUE)
data$grade = get_grades(data$average_score)
data = data[,-c(6,7,8,9)]
n=dim(data)[1]
set.seed(12345)
id=sample(1:n, floor(n*0.75))
train=data[id,]
test=data[-id,]
trainG = train[,-c(6,7,8,9)]
#nb_model_G = naiveBayes(score_grp_G ~., data = trainG)
nb_model_G = train(x=trainG[,-c(6)],y=trainG[,6], "nb", trControl = trainControl(method = "cv", number = G))
#nb_model_G = naiveBayes(score_grp_G ~., data = trainG)
nb_model_G = train(x=trainG[,-c(6)],y=trainG[,6], "nb", trControl = trainControl(method = "cv", number = 10))
test_preds = predict(nb_model_G, testG)
testG = test[,-c(6,7,8,9)]
test_preds = predict(nb_model_G, testG)
conf_m = table(testG$grade, test_preds)
print(paste("Misclassification rate is",1 - sum(diag(conf_m))/sum(conf_m)))
table(testG$grade, test_preds)
help(predict)
help(caret.predict)
help(predict.caret)
test_preds = predict(nb_model_G, testG, type="probabilites")
test_preds = predict(nb_model_G, testG, type="prob")
#nb_model_G = naiveBayes(score_grp_G ~., data = trainG)
nb_model_G = train(x=trainG[,-c(5,6)],y=trainG[,6], "nb", trControl = trainControl(method = "cv", number = 10))
test_preds = predict(nb_model_G, testG, type="prob")
conf_m = table(testG$grade, test_preds)
test_preds = predict(nb_model_G, testG)
conf_m = table(testG$grade, test_preds)
print(paste("Misclassification rate is",1 - sum(diag(conf_m))/sum(conf_m)))
#nb_model_G = naiveBayes(score_grp_G ~., data = trainG)
nb_model_G = train(x=trainG[,-c(1,2,3,5,6)],y=trainG[,6], "nb", trControl = trainControl(method = "cv", number = 10))
test_preds = predict(nb_model_G, testG)
#nb_model_G = naiveBayes(score_grp_G ~., data = trainG)
nb_model_G = train(x=trainG[,-c(1,2,3,5,6)],y=trainG[,6], "nb", trControl = trainControl(method = "cv", number = 10))
#nb_model_G = naiveBayes(score_grp_G ~., data = trainG)
nb_model_G = train(x=trainG[,-c(1,2,3,6)],y=trainG[,6], "nb", trControl = trainControl(method = "cv", number = 10))
test_preds = predict(nb_model_G, testG)
conf_m = table(testG$grade, test_preds)
print(paste("Misclassification rate is",1 - sum(diag(conf_m))/sum(conf_m)))
#nb_model_G = naiveBayes(score_grp_G ~., data = trainG)
nb_model_G = train(x=trainG[,-c(1,6)],y=trainG[,6], "nb", trControl = trainControl(method = "cv", number = 10))
test_preds = predict(nb_model_G, testG)
conf_m = table(testG$grade, test_preds)
print(paste("Misclassification rate is",1 - sum(diag(conf_m))/sum(conf_m)))
#nb_model_G = naiveBayes(score_grp_G ~., data = trainG)
nb_model_G = train(x=trainG[,-c(1,2,6)],y=trainG[,6], "nb", trControl = trainControl(method = "cv", number = 10))
test_preds = predict(nb_model_G, testG)
conf_m = table(testG$grade, test_preds)
print(paste("Misclassification rate is",1 - sum(diag(conf_m))/sum(conf_m)))
#nb_model_G = naiveBayes(score_grp_G ~., data = trainG)
nb_model_G = train(x=trainG[,-c(2,6)],y=trainG[,6], "nb", trControl = trainControl(method = "cv", number = 10))
test_preds = predict(nb_model_G, testG)
conf_m = table(testG$grade, test_preds)
print(paste("Misclassification rate is",1 - sum(diag(conf_m))/sum(conf_m)))
#nb_model_G = naiveBayes(score_grp_G ~., data = trainG)
nb_model_G = train(x=trainG[,-c(5,6)],y=trainG[,6], "nb", trControl = trainControl(method = "cv", number = 10))
test_preds = predict(nb_model_G, testG)
conf_m = table(testG$grade, test_preds)
print(paste("Misclassification rate is",1 - sum(diag(conf_m))/sum(conf_m)))
train10 = train[,-c(6,7,8,10)]
test10 = test[,-c(6,7,8,10)]
#nb_model_10 = naiveBayes(score_grp_10 ~., data = train10)
nb_model_10 = train(x=train10[,-c(6)],y=train10[,6], "nb", trControl = trainControl(method = "cv", number = 10))
test_preds = predict(nb_model_10, test10)
conf_m = table(test10$score_grp_10, test_preds)
print(paste("Misclassification rate is",1 - sum(diag(conf_m))/sum(conf_m)))
calc_max_MSE(conf_m)
train4 = train[,-c(6,7,9,10)]
test4 = train[,-c(6,7,9,10)]
#nb_model_4 = naiveBayes(score_grp_4 ~., data = train4)
nb_model_4 = train(x=train4[,-c(6)],y=train4[,6], "nb", trControl = trainControl(method = "cv", number = 10))
test_preds = predict(nb_model_4, test4)
conf_m = table(test4$score_grp_4, test_preds)
print(paste("Misclassification rate is",1 - sum(diag(conf_m))/sum(conf_m)))
calc_max_MSE(conf_m)
train2 = train[,-c(6,8,9,10)]
test2 = test[,-c(6,8,9,10)]
#nb_model_2 = naiveBayes(score_grp_2 ~., data = train2)
nb_model_2 = train(x=train2[,-c(6)],y=train2[,6], "nb", trControl = trainControl(method = "cv", number = 10))
test_preds = predict(nb_model_2, test2)
conf_m = table(test2$score_grp_2, test_preds)
print(paste("Misclassification rate is",1 - sum(diag(conf_m))/sum(conf_m)))
calc_max_MSE(conf_m)
train5 = train[,-c(7,8,9,10)]
test5 = test[,-c(7,8,9,10)]
#nb_model_5 = naiveBayes(score_grp_5~., data = train5)
nb_model_5 = train(x=train5[,-c(6)],y=train5[,6], "nb", trControl = trainControl(method = "cv", number = 10))
test_preds = predict(nb_model_5, test5)
conf_m = table(Actual = test5$score_grp_5, Predicted = test_preds)
print(paste("Misclassification rate is",1 - sum(diag(conf_m))/sum(conf_m)))
calc_max_MSE(conf_m)
train2 = train[,-c(6,8,9,10)]
test2 = test[,-c(6,8,9,10)]
#nb_model_2 = naiveBayes(score_grp_2 ~., data = train2)
nb_model_2 = train(x=train2[,-c(6)],y=train2[,6], "nb", trControl = trainControl(method = "cv", number = 10))
data = read.csv("StudentsPerformance.csv")
data$average_score = calc_avg(data)
data$score_grp_5 = cut(data$reading.score, breaks = seq(0,100,by = 5), right = TRUE)
data$score_grp_5 = factor(data$score_grp_5, levels = levels(data$score_grp_5)[table(data$score_grp_5) > 0])
data$score_grp_2 = cut(data$reading.score, breaks = seq(0,100,by = 2), right = TRUE)
data$score_grp_2 = factor(data$score_grp_2, levels = levels(data$score_grp_2)[table(data$score_grp_2) > 0])
data$score_grp_4 = cut(data$reading.score, breaks = seq(0,100,by = 4), right = TRUE)
data$score_grp_4 = factor(data$score_grp_4, levels = levels(data$score_grp_4)[table(data$score_grp_4) > 0])
data$score_grp_10 = cut(data$reading.score, breaks = seq(0,100,by = 10), right = TRUE)
data$grade = get_grades(data$average_score)
data = data[,-c(6,7,8,9)]
n=dim(data)[1]
set.seed(12345)
set.seed(123)
id=sample(1:n, floor(n*0.8))
train=data[id,]
test=data[-id,]
#library(e1071)
library(caret)
train5 = train[,-c(7,8,9,10)]
test5 = test[,-c(7,8,9,10)]
#nb_model_5 = naiveBayes(score_grp_5~., data = train5)
nb_model_5 = train(x=train5[,-c(6)],y=train5[,6], "nb", trControl = trainControl(method = "cv", number = 10))
test_preds = predict(nb_model_5, test5)
conf_m = table(Actual = test5$score_grp_5, Predicted = test_preds)
print(paste("Misclassification rate is",1 - sum(diag(conf_m))/sum(conf_m)))
calc_max_MSE(conf_m)
train2 = train[,-c(6,8,9,10)]
test2 = test[,-c(6,8,9,10)]
#nb_model_2 = naiveBayes(score_grp_2 ~., data = train2)
nb_model_2 = train(x=train2[,-c(6)],y=train2[,6], "nb", trControl = trainControl(method = "cv", number = 10))
test_preds = predict(nb_model_2, test2)
conf_m = table(test2$score_grp_2, test_preds)
print(paste("Misclassification rate is",1 - sum(diag(conf_m))/sum(conf_m)))
calc_max_MSE(conf_m)
train4 = train[,-c(6,7,9,10)]
test4 = train[,-c(6,7,9,10)]
#nb_model_4 = naiveBayes(score_grp_4 ~., data = train4)
nb_model_4 = train(x=train4[,-c(6)],y=train4[,6], "nb", trControl = trainControl(method = "cv", number = 10))
test_preds = predict(nb_model_4, test4)
conf_m = table(test4$score_grp_4, test_preds)
print(paste("Misclassification rate is",1 - sum(diag(conf_m))/sum(conf_m)))
calc_max_MSE(conf_m)
train10 = train[,-c(6,7,8,10)]
test10 = test[,-c(6,7,8,10)]
#nb_model_10 = naiveBayes(score_grp_10 ~., data = train10)
nb_model_10 = train(x=train10[,-c(6)],y=train10[,6], "nb", trControl = trainControl(method = "cv", number = 10))
test_preds = predict(nb_model_10, test10)
conf_m = table(test10$score_grp_10, test_preds)
print(paste("Misclassification rate is",1 - sum(diag(conf_m))/sum(conf_m)))
calc_max_MSE(conf_m)
trainG = train[,-c(6,7,8,9)]
testG = test[,-c(6,7,8,9)]
#nb_model_G = naiveBayes(score_grp_G ~., data = trainG)
nb_model_G = train(x=trainG[,-c(5,6)],y=trainG[,6], "nb", trControl = trainControl(method = "cv", number = 10))
test_preds = predict(nb_model_G, testG)
conf_m = table(testG$grade, test_preds)
print(paste("Misclassification rate is",1 - sum(diag(conf_m))/sum(conf_m)))
calc_max_MSE(conf_m)
