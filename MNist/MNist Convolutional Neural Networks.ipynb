{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST data set processing - classifying handwritten digits\n",
    "\n",
    "\n",
    "Let's classify some handwritten digits! In this kernel, I will be implementing two neural nets; one classical, LeNet-5 architecture, and another architecture not too advanced. \n",
    "\n",
    "\n",
    "## Prepare data, define functions etc.\n",
    "First, let's preprocess and prepare it a bit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def create_submission(test_preds, file_name = \"submission.csv\"):\n",
    "    submission = pd.concat([pd.Series(np.arange(1,len(test_preds) + 1)),pd.Series(test_preds)], axis = 1)\n",
    "    submission.columns = ['ImageId','Label']\n",
    "    submission.to_csv(file_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train = pd.read_csv(\"digit-recognizer/train.csv\")\n",
    "test = pd.read_csv(\"digit-recognizer/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py:5201: ResourceWarning: unclosed file <_io.TextIOWrapper name='/Users/filipcornell/.keras/keras.json' mode='r' encoding='UTF-8'>\n",
      "  _config = json.load(open(_config_path))\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.regularizers import l2 # Perhaps not use?\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dropout, Dense, Activation, Embedding, Input, Reshape, Flatten, UpSampling2D,AveragePooling2D,Layer\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "x_train = np.array(train.drop([\"label\"], axis = 1))\n",
    "y_train = np.array(train['label'])\n",
    "x_test = np.array(test)\n",
    "# Convert into a nice input shape for the neural net. \n",
    "x_train = x_train.reshape(42000,28,28,1)\n",
    "x_test = x_test.reshape(28000,28,28,1)\n",
    "\n",
    "# Convert the training labels to categorical. \n",
    "y_train = to_categorical(y_train)\n",
    "#y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the first architecture\n",
    "\n",
    "Let's implement the first architecture in the task given. I am not sure who first came up with this architecture, but if you know, I would be happy to receive information to reference him or her. The implementation can be seen below. Below we can also see a summary of the network which makes its structure quite clear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 4)         104       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 8)         520       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 12)          1548      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 588)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               117800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 121,982\n",
      "Trainable params: 121,982\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=4, kernel_size = (5,5), strides = 1, padding = \"same\",  input_shape=(28,28,1), activation =\"tanh\"))\n",
    "model.add(Conv2D(filters=8, kernel_size = (4,4), strides = 2, padding = \"same\", activation = \"relu\"))\n",
    "model.add(Conv2D(filters=12, kernel_size = (4,4), strides = 2, padding = \"same\", activation = \"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 200))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units = 10, activation = \"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy',optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "42000/42000 [==============================] - 30s 716us/step - loss: 0.2536 - acc: 0.9206\n",
      "Epoch 2/10\n",
      "42000/42000 [==============================] - 26s 630us/step - loss: 0.1012 - acc: 0.9682\n",
      "Epoch 3/10\n",
      "42000/42000 [==============================] - 28s 671us/step - loss: 0.0818 - acc: 0.9750\n",
      "Epoch 4/10\n",
      "42000/42000 [==============================] - 25s 596us/step - loss: 0.0724 - acc: 0.9767\n",
      "Epoch 5/10\n",
      "42000/42000 [==============================] - 23s 559us/step - loss: 0.0653 - acc: 0.9798\n",
      "Epoch 6/10\n",
      "42000/42000 [==============================] - 25s 594us/step - loss: 0.0648 - acc: 0.9789\n",
      "Epoch 7/10\n",
      "42000/42000 [==============================] - 25s 599us/step - loss: 0.0536 - acc: 0.9829\n",
      "Epoch 8/10\n",
      "42000/42000 [==============================] - 24s 561us/step - loss: 0.0519 - acc: 0.9834\n",
      "Epoch 9/10\n",
      "42000/42000 [==============================] - 24s 580us/step - loss: 0.0533 - acc: 0.9834\n",
      "Epoch 10/10\n",
      "42000/42000 [==============================] - 30s 705us/step - loss: 0.0467 - acc: 0.9854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x123583cc0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "model.fit(x_train,y_train, epochs = n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_preds = model.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "def get_preds(preds):\n",
    "    return np.apply_along_axis(np.argmax, 1, preds)\n",
    "\n",
    "\n",
    "create_submission(get_preds(y_preds), file_name = \"submission_regular_CNN.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, a great score actually! However, those last few percentages could probably be reached:\n",
    "\n",
    "- By applying regularization method, such as l2-regularization and dropout layers. \n",
    "- Using a more thorough validation method such as K-fold cross-validation during training, or simply having a validation set. \n",
    "- Optimizing hypteparameters, such as the learning rate for *ADAM*. \n",
    "\n",
    "I leave those improvements for a day with more time. Also, I think that this architecture is not as good as the coming one, so I think I will leave this one for now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet-5 Architecture\n",
    "\n",
    "Okay, now we should implement the LeNet-5 architecture. This architecture is a known one, and more information on it can be found [here](https://engmrk.com/lenet-5-a-classic-cnn-architecture/). However, that link seems to have implemented it differently from the way I have; it uses a SoftMax activation function in the last layer, which I am not sure whether it is correct. \n",
    "\n",
    "\n",
    "First, some googling led me to realize that there is no RBFLayer predefined in Keras which is the activation function used in the last layer in the LeNet-5 archticeture, so we should define our own. There was a [finished implementation on StackOverflow](https://stackoverflow.com/questions/53855941/how-to-implement-rbf-activation-function-in-keras), so I simply took that. Thank you [today@StackOverflow](https://stackoverflow.com/users/2099607/today). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This implementation is taken from StackOverflow and was posted by today@StackOverflow. All kudos to him. \n",
    "# It can be found at https://stackoverflow.com/questions/53855941/how-to-implement-rbf-activation-function-in-keras\n",
    "from keras.layers import Layer\n",
    "from keras import backend as K\n",
    "\n",
    "class RBFLayer(Layer):\n",
    "    def __init__(self, units, gamma, **kwargs):\n",
    "        super(RBFLayer, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.gamma = K.cast_to_floatx(gamma)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.mu = self.add_weight(name='mu',\n",
    "                                  shape=(int(input_shape[1]), self.units),\n",
    "                                  initializer='uniform',\n",
    "                                  trainable=True)\n",
    "        super(RBFLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        diff = K.expand_dims(inputs) - self.mu\n",
    "        l2 = K.sum(K.pow(diff,2), axis=1)\n",
    "        res = K.exp(-1 * self.gamma * l2)\n",
    "        return res\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.units)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 10, 16)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 1, 1, 120)         48120     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 1, 120)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "rbf_layer_1 (RBFLayer)       (None, 10)                840       \n",
      "=================================================================\n",
      "Total params: 61,696\n",
      "Trainable params: 61,696\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "le_net5 = Sequential()\n",
    "le_net5.add(Conv2D(filters = 6, kernel_size = (5,5), strides = 1,activation = \"tanh\", input_shape=(28,28,1), padding = \"same\"))\n",
    "le_net5.add(AveragePooling2D(pool_size=(2,2), strides = 2, padding = \"valid\"))\n",
    "le_net5.add(Conv2D(filters = 16, kernel_size = (5,5), strides = 1, activation = \"tanh\"))\n",
    "le_net5.add(Dropout(0.05))\n",
    "le_net5.add(AveragePooling2D(pool_size=(2,2), strides = 2, padding = \"same\"))\n",
    "le_net5.add(Conv2D(filters = 120, kernel_size = (5,5), strides = 1, activation = \"tanh\"))\n",
    "le_net5.add(Dropout(0.05))\n",
    "le_net5.add(Flatten())\n",
    "le_net5.add(Dense(units = 84, activation = \"tanh\"))\n",
    "le_net5.add(RBFLayer(10, gamma=0.5))\n",
    "le_net5.compile(loss='categorical_crossentropy',optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "le_net5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "42000/42000 [==============================] - 32s 757us/step - loss: 0.2054 - acc: 0.9432\n",
      "Epoch 2/10\n",
      "42000/42000 [==============================] - 31s 728us/step - loss: 0.0700 - acc: 0.9779\n",
      "Epoch 3/10\n",
      "42000/42000 [==============================] - 34s 807us/step - loss: 0.0535 - acc: 0.9829\n",
      "Epoch 4/10\n",
      "42000/42000 [==============================] - 32s 761us/step - loss: 0.0450 - acc: 0.9853\n",
      "Epoch 5/10\n",
      "42000/42000 [==============================] - 26s 616us/step - loss: 0.0408 - acc: 0.9864\n",
      "Epoch 6/10\n",
      "42000/42000 [==============================] - 24s 582us/step - loss: 0.0324 - acc: 0.9894\n",
      "Epoch 7/10\n",
      "42000/42000 [==============================] - 25s 599us/step - loss: 0.0300 - acc: 0.9905\n",
      "Epoch 8/10\n",
      "42000/42000 [==============================] - 25s 599us/step - loss: 0.0302 - acc: 0.9904\n",
      "Epoch 9/10\n",
      "42000/42000 [==============================] - 25s 590us/step - loss: 0.0229 - acc: 0.9925\n",
      "Epoch 10/10\n",
      "42000/42000 [==============================] - 24s 573us/step - loss: 0.0235 - acc: 0.9918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x127dd6160>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_net5.fit(x_train, y_train, epochs = n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = le_net5.predict(x_test)\n",
    "\n",
    "create_submission(get_preds(y_preds), \"submission_leNet55.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network also had a great accuracy. Nice. However, the accuracy seems to land at around 0.989, close to 0.99 on the training set, indicating it might get stuck in a local optima. I applied dropout, but none seem to increase the test score to go above 0.985. If anyone has any feedback and improvement suggestions, I would be delighted to receive it! \n",
    "\n",
    "Thank you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
